{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e320fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577f6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864dc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1feb35",
   "metadata": {},
   "source": [
    "## SMILES to QMSE-Compatible Molecular Data\n",
    "To proceed with starting from SMILES strings and converting them into the detailed molecular representations required for Quantum Molecular Structure Encoding (QMSE), here is a step-by-step approach with Python usage leveraging RDKit:\n",
    "\n",
    "1. Input Canonical SMILES\n",
    "2. Generate 3D Conformers for accurate geometry\n",
    "3. Extract bond orders and stereochemistry\n",
    "4. Calculate Isomerism Parameters `epsilon_D` and `epsilon_T`\n",
    "5. Construct Hybrid Coulomb-Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f668119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>...</th>\n",
       "      <th>zpve</th>\n",
       "      <th>u0</th>\n",
       "      <th>u298</th>\n",
       "      <th>h298</th>\n",
       "      <th>g298</th>\n",
       "      <th>cv</th>\n",
       "      <th>u0_atom</th>\n",
       "      <th>u298_atom</th>\n",
       "      <th>h298_atom</th>\n",
       "      <th>g298_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gdb_1</td>\n",
       "      <td>C</td>\n",
       "      <td>157.71180</td>\n",
       "      <td>157.709970</td>\n",
       "      <td>157.706990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478930</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "      <td>6.469</td>\n",
       "      <td>-395.999595</td>\n",
       "      <td>-398.643290</td>\n",
       "      <td>-401.014647</td>\n",
       "      <td>-372.471772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gdb_2</td>\n",
       "      <td>N</td>\n",
       "      <td>293.60975</td>\n",
       "      <td>293.541110</td>\n",
       "      <td>191.393970</td>\n",
       "      <td>1.6256</td>\n",
       "      <td>9.46</td>\n",
       "      <td>-0.2570</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.3399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034358</td>\n",
       "      <td>-56.525887</td>\n",
       "      <td>-56.523026</td>\n",
       "      <td>-56.522082</td>\n",
       "      <td>-56.544961</td>\n",
       "      <td>6.316</td>\n",
       "      <td>-276.861363</td>\n",
       "      <td>-278.620271</td>\n",
       "      <td>-280.399259</td>\n",
       "      <td>-259.338802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gdb_3</td>\n",
       "      <td>O</td>\n",
       "      <td>799.58812</td>\n",
       "      <td>437.903860</td>\n",
       "      <td>282.945450</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-0.2928</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>-76.404702</td>\n",
       "      <td>-76.401867</td>\n",
       "      <td>-76.400922</td>\n",
       "      <td>-76.422349</td>\n",
       "      <td>6.002</td>\n",
       "      <td>-213.087624</td>\n",
       "      <td>-213.974294</td>\n",
       "      <td>-215.159658</td>\n",
       "      <td>-201.407171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gdb_4</td>\n",
       "      <td>C#C</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.28</td>\n",
       "      <td>-0.2845</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>-77.308427</td>\n",
       "      <td>-77.305527</td>\n",
       "      <td>-77.304583</td>\n",
       "      <td>-77.327429</td>\n",
       "      <td>8.574</td>\n",
       "      <td>-385.501997</td>\n",
       "      <td>-387.237686</td>\n",
       "      <td>-389.016047</td>\n",
       "      <td>-365.800724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gdb_5</td>\n",
       "      <td>C#N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>44.593883</td>\n",
       "      <td>44.593883</td>\n",
       "      <td>2.8937</td>\n",
       "      <td>12.99</td>\n",
       "      <td>-0.3604</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>-93.411888</td>\n",
       "      <td>-93.409370</td>\n",
       "      <td>-93.408425</td>\n",
       "      <td>-93.431246</td>\n",
       "      <td>6.278</td>\n",
       "      <td>-301.820534</td>\n",
       "      <td>-302.906752</td>\n",
       "      <td>-304.091489</td>\n",
       "      <td>-288.720028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  mol_id smiles          A           B           C      mu  alpha    homo  \\\n",
       "0  gdb_1      C  157.71180  157.709970  157.706990  0.0000  13.21 -0.3877   \n",
       "1  gdb_2      N  293.60975  293.541110  191.393970  1.6256   9.46 -0.2570   \n",
       "2  gdb_3      O  799.58812  437.903860  282.945450  1.8511   6.31 -0.2928   \n",
       "3  gdb_4    C#C    0.00000   35.610036   35.610036  0.0000  16.28 -0.2845   \n",
       "4  gdb_5    C#N    0.00000   44.593883   44.593883  2.8937  12.99 -0.3604   \n",
       "\n",
       "     lumo     gap  ...      zpve         u0       u298       h298       g298  \\\n",
       "0  0.1171  0.5048  ...  0.044749 -40.478930 -40.476062 -40.475117 -40.498597   \n",
       "1  0.0829  0.3399  ...  0.034358 -56.525887 -56.523026 -56.522082 -56.544961   \n",
       "2  0.0687  0.3615  ...  0.021375 -76.404702 -76.401867 -76.400922 -76.422349   \n",
       "3  0.0506  0.3351  ...  0.026841 -77.308427 -77.305527 -77.304583 -77.327429   \n",
       "4  0.0191  0.3796  ...  0.016601 -93.411888 -93.409370 -93.408425 -93.431246   \n",
       "\n",
       "      cv     u0_atom   u298_atom   h298_atom   g298_atom  \n",
       "0  6.469 -395.999595 -398.643290 -401.014647 -372.471772  \n",
       "1  6.316 -276.861363 -278.620271 -280.399259 -259.338802  \n",
       "2  6.002 -213.087624 -213.974294 -215.159658 -201.407171  \n",
       "3  8.574 -385.501997 -387.237686 -389.016047 -365.800724  \n",
       "4  6.278 -301.820534 -302.906752 -304.091489 -288.720028  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('qm9.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c82d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QMSEMatrix(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    Chem.AssignStereochemistry(mol, cleanIt=True, force=True)\n",
    "    AllChem.EmbedMolecule(mol, randomSeed = 67)\n",
    "    AllChem.MMFFOptimizeMolecule(mol)\n",
    "    conf = mol.GetConformer()\n",
    "    #coords = [conf.GetAtomPosition(i) for i in range(mol.GetNumAtoms())]\n",
    "    bond_orders_and_stereo = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        order = bond.GetBondTypeAsDouble()\n",
    "        stereo = Chem.BondStereo.STEREONONE\n",
    "        epsilon_D = 1\n",
    "        if bond.GetBondType() == Chem.BondType.DOUBLE and bond.GetStereo() == Chem.BondStereo.STEREOZ:\n",
    "            epsilon_D = -1\n",
    "        bond_orders_and_stereo.append((i, j, order, epsilon_D))\n",
    "    chiral_centers = Chem.FindMolChiralCenters(mol, includeUnassigned=True)\n",
    "    epsilon_T = {}\n",
    "    for atom_idx, chirality in chiral_centers:\n",
    "        if chirality == Chem.CHIRALITY_S:\n",
    "            epsilon_T[atom_idx] = -1\n",
    "        else:\n",
    "            epsilon_T[atom_idx] = 1\n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    M = np.zeros((num_atoms, num_atoms))\n",
    "    Z = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        M[i, i] = 0.5 * epsilon_T.get(i, 1) * (Z[i] ** 3)\n",
    "\n",
    "    for i, j, order, epsilon_D in bond_orders_and_stereo:\n",
    "        M[i, j] = M[j, i] = (epsilon_D * Z[i] * Z[j]) / order\n",
    "        \n",
    "    return M, bond_orders_and_stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f7e252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[108. ,  36. ,  48. ,   6. ,   6. ,   0. ,   0. ],\n",
       "         [ 36. , 108. ,  48. ,   0. ,   0. ,   6. ,   6. ],\n",
       "         [ 48. ,  48. , 256. ,   0. ,   0. ,   0. ,   0. ],\n",
       "         [  6. ,   0. ,   0. ,   0.5,   0. ,   0. ,   0. ],\n",
       "         [  6. ,   0. ,   0. ,   0. ,   0.5,   0. ,   0. ],\n",
       "         [  0. ,   6. ,   0. ,   0. ,   0. ,   0.5,   0. ],\n",
       "         [  0. ,   6. ,   0. ,   0. ,   0. ,   0. ,   0.5]], requires_grad=True),\n",
       " [(0, 1, 1.0, 1),\n",
       "  (1, 2, 1.0, 1),\n",
       "  (2, 0, 1.0, 1),\n",
       "  (0, 3, 1.0, 1),\n",
       "  (0, 4, 1.0, 1),\n",
       "  (1, 5, 1.0, 1),\n",
       "  (1, 6, 1.0, 1)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QMSEMatrix(df.iloc[16]['smiles'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2443420",
   "metadata": {},
   "source": [
    "## Quantum Circuit Encoding of the QMSE + MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22cd51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixedQMSECircuit(\n",
    "    matrix,\n",
    "    edge_list,\n",
    "    params,\n",
    "    n_qubits: int,\n",
    "    n_layers: int,\n",
    "    dev=None\n",
    "):\n",
    "    if not dev: dev = qml.device('default.qubit', wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def applyCircuit():\n",
    "        # Initial QMSE encoding - RY rotations per node\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(matrix[i, i], wires=i) \n",
    "        \n",
    "        # Initial bond IsingXX rotations\n",
    "        for i in range(n_qubits):\n",
    "            for j in range(i+1, n_qubits):\n",
    "                if matrix[i, j] != 0:\n",
    "                    qml.IsingXX(matrix[i, j], wires=[i,j])\n",
    "        \n",
    "        # Message passing layers\n",
    "        for layer in range(n_layers):\n",
    "            for edge_idx, (i, j, _, _) in enumerate(edge_list):\n",
    "                qml.IsingXX(params[layer, edge_idx], wires=[i, j])\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(params[layer, i + len(edge_list)], wires=i)\n",
    "        \n",
    "        # Collect per-node features (2 observables per qubit: Z, X)\n",
    "        node_feats = []\n",
    "        for i in range(n_qubits):\n",
    "            node_feats.append(qml.expval(qml.PauliZ(i)))\n",
    "            node_feats.append(qml.expval(qml.PauliX(i)))\n",
    "        \n",
    "        # Collect per-bond features (Z_i Z_j correlators)\n",
    "        bond_feats = []\n",
    "        for i, j, _, _ in edge_list:\n",
    "            bond_feats.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(j)))\n",
    "        return node_feats, bond_feats   # tuple of two tensors\n",
    "\n",
    "    return applyCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3835c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysteryMatrix, mysteryEL = QMSEMatrix(df.iloc[16]['smiles'])\n",
    "n_qubits = len(mysteryMatrix)\n",
    "n_layers = 4 # based on lit, 3-5 provides the best results\n",
    "num_params = len(mysteryEL) + n_qubits\n",
    "mysteryWeight = torch.randn(n_layers, num_params, requires_grad=True)\n",
    "mysteryCircuit = FixedQMSECircuit(\n",
    "    mysteryMatrix,\n",
    "    mysteryEL,\n",
    "    mysteryWeight,\n",
    "    n_qubits,\n",
    "    n_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2f75be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcui/Downloads/ElectroDragon/coconut/lib/python3.11/site-packages/pennylane/math/interface_utils.py:136: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow, PyTorch, and Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nodeFeatures, bondFeatures = mysteryCircuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8afd6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeFeatures = torch.stack(nodeFeatures).reshape(n_qubits, 2).to(torch.float32)   # [n_qubits, 2]\n",
    "bondFeatures = torch.stack(bondFeatures).reshape(len(mysteryEL), 1).to(torch.float32)  # [n_bonds, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41f3369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0549],\n",
       "        [-0.0833],\n",
       "        [-0.4017],\n",
       "        [-0.3263],\n",
       "        [ 0.3957],\n",
       "        [ 0.2802],\n",
       "        [ 0.5132]], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bondFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "084e31ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4368, -0.1431],\n",
       "        [-0.0837,  0.0275],\n",
       "        [ 0.9042,  0.0248],\n",
       "        [ 0.5308, -0.5608],\n",
       "        [-0.9088, -0.2330],\n",
       "        [-0.3431, -0.0837],\n",
       "        [-0.3344,  0.3946]], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodeFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387540fb",
   "metadata": {},
   "source": [
    "## Classical Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c4629d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim=64, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, node_feats, bond_feats):\n",
    "        \"\"\"\n",
    "        node_feats: tensor [n_nodes, F_node]\n",
    "        bond_feats: tensor [n_bonds, F_bond]\n",
    "        returns: tensor [1] predicted property\n",
    "        \"\"\"\n",
    "        # Compute mean, max, std pooling along node/bond dimension (dim=0)\n",
    "        n_mean = node_feats.mean(dim=0)\n",
    "        n_max  = node_feats.max(dim=0).values\n",
    "        n_std  = node_feats.std(dim=0)\n",
    "\n",
    "        b_mean = bond_feats.mean(dim=0)\n",
    "        b_max  = bond_feats.max(dim=0).values\n",
    "        b_std  = bond_feats.std(dim=0)\n",
    "\n",
    "        # Concatenate all pooled statistics into a fixed-length vector\n",
    "        pooled_features = torch.cat([n_mean, n_max, n_std, b_mean, b_max, b_std], dim=0)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        return self.net(pooled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71c5c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=64, bias=True)\n",
      "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): SiLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): SiLU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "readout = MLP(feature_dim=9)\n",
    "print(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76bc3e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1076], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysteryTensors = (nodeFeatures, bondFeatures)\n",
    "mysteryValue = readout(*mysteryTensors)\n",
    "mysteryValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd36f06",
   "metadata": {},
   "source": [
    "## Now We Combine Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5541049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMPNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_qubits: int = 16,\n",
    "        max_bonds: int = 120,\n",
    "        num_layers: int = 4,\n",
    "        feature_dim: int = 9,      # 3*(2 node feats) + 3*(1 bond feat)\n",
    "        hidden_dim: int = 64,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.max_qubits = max_qubits\n",
    "        self.max_bonds = max_bonds\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Register quantum message-passing parameters\n",
    "        self.quantum_params = nn.Parameter(\n",
    "            torch.randn(num_layers, max_qubits + max_bonds, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        # Predefine one device and QNode for the maximum size\n",
    "        self.dev = qml.device(\"default.qubit\", wires=max_qubits)\n",
    "\n",
    "        @qml.qnode(self.dev, interface=\"torch\")\n",
    "        def _quantum_forward(matrix, edge_list, n_qubits, n_bonds):\n",
    "            # 1) QMSE encoding on active qubits\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(matrix[i, i], wires=i)\n",
    "            # 2) Initial bond rotations\n",
    "            for i, j, _, _ in edge_list:\n",
    "                qml.IsingXX(matrix[i, j], wires=[i, j])\n",
    "            # 3) Message-passing layers\n",
    "            for layer in range(self.num_layers):\n",
    "                for edge_idx, (i, j, _, _) in enumerate(edge_list):\n",
    "                    qml.IsingXX(self.quantum_params[layer, edge_idx], wires=[i, j])\n",
    "                for i in range(n_qubits):\n",
    "                    param_idx = len(edge_list) + i\n",
    "                    qml.RY(self.quantum_params[layer, param_idx], wires=i)\n",
    "            # 4) Gather fixed-length node & bond expectation lists\n",
    "            node_feats = []\n",
    "            for i in range(self.max_qubits):\n",
    "                if i < n_qubits:\n",
    "                    node_feats.append(qml.expval(qml.PauliZ(i)))\n",
    "                    node_feats.append(qml.expval(qml.PauliX(i)))\n",
    "                else:\n",
    "                    node_feats.extend([0.0, 0.0])\n",
    "            bond_feats = []\n",
    "            for b in range(self.max_bonds):\n",
    "                if b < n_bonds:\n",
    "                    i, j, _, _ = edge_list[b]\n",
    "                    bond_feats.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(j)))\n",
    "                else:\n",
    "                    bond_feats.append(0.0)\n",
    "            return node_feats, bond_feats\n",
    "\n",
    "        self._quantum_forward = _quantum_forward\n",
    "\n",
    "        # Classical MLP with mean/max/std pooling\n",
    "        self.MLP = MLP(feature_dim, hidden_dim, dropout)\n",
    "\n",
    "    def forward(self, matrix, edge_list):\n",
    "        \"\"\"\n",
    "        matrix:  [n_qubits, n_qubits] QMSE matrix for this molecule\n",
    "        edge_list: list of (i, j, order, stereo) for this molecule\n",
    "        \"\"\"\n",
    "        n_qubits = matrix.shape[0]\n",
    "        n_bonds = len(edge_list)\n",
    "\n",
    "        # 1) Run the single QNode with actual sizes\n",
    "        node_list, bond_list = self._quantum_forward(\n",
    "            matrix, edge_list, n_qubits, n_bonds\n",
    "        )\n",
    "\n",
    "        # 2) Stack into fixed-size tensors\n",
    "        node_feats = torch.stack(node_list).reshape(self.max_qubits, 2)\n",
    "        bond_feats = torch.stack(bond_list).reshape(self.max_bonds, 1)\n",
    "\n",
    "        # 3) Select only active entries to avoid padding bias\n",
    "        active_node_feats = node_feats[:n_qubits]\n",
    "        active_bond_feats = bond_feats[:n_bonds] if n_bonds > 0 else torch.zeros((0, 1))\n",
    "\n",
    "        # 4) Pool and predict via MLP\n",
    "        prediction = self.MLP(active_node_feats, active_bond_feats)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d65c3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QMPNN(\n",
      "  (MLP): MLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=9, out_features=64, bias=True)\n",
      "      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): SiLU()\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): SiLU()\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MessagePassingNetwork = QMPNN()\n",
    "print(MessagePassingNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b992f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coconut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
